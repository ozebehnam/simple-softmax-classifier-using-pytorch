# -*- coding: utf-8 -*-
"""Softmax Classifier using Pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KFmDnt0lHsvz4UVPRDXz15xttlVp7CUC
"""

import numpy as np
import pandas as pd
import torch
from torch.autograd import Variable

model = torch.nn.Sequential(
    torch.nn.Linear(3,3, bias=True),
    torch.nn.ReLU(),
    torch.nn.Linear(3,3, bias=True),
    torch.nn.ReLU(),
    torch.nn.Linear(3,3, bias=True),
    torch.nn.ReLU(),
    torch.nn.Softmax(dim=1)
)

print(model)


data = pd.read_csv("softmax_sample.csv")

data_x = np.array(data[["plastic","paper","glass"]], dtype=np.float32)
data_y = np.array(data[["student","worker","elder"]], dtype=np.float32)
x_train = torch.from_numpy(data_x)
y_train = torch.from_numpy(data_y)
num_epoch = 1000

loss_function = torch.nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)

for epoch in range(num_epoch):
    input = Variable(x_train)
    target = Variable(y_train)

    # forward
    out = model(input)
    loss = loss_function(out, target)

    # backward
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # show
    print('Epoch[{}/{}], loss: {:.6f}'
          .format(epoch + 1, num_epoch, loss.data.item()))

print(model(torch.tensor([[500, 500, 500]], dtype=torch.float32)))